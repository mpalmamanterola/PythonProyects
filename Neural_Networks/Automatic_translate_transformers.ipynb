{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83ef70f-c8a2-42c9-8fb0-577f82ee3927",
   "metadata": {
    "executionInfo": {
     "elapsed": 3155,
     "status": "ok",
     "timestamp": 1654212626689,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "c83ef70f-c8a2-42c9-8fb0-577f82ee3927"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "929aab9f-63d4-4d49-bbe6-03efefba925f",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1654212626689,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "929aab9f-63d4-4d49-bbe6-03efefba925f"
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential([layers.Dense(ff_dim, activation = \"relu\"), layers.Dense(embed_dim),])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training = training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training = training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6f5033f-03c1-459f-8e61-18695f3bdc63",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1654212626690,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "b6f5033f-03c1-459f-8e61-18695f3bdc63"
   },
   "outputs": [],
   "source": [
    "class Encoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_layers, num_heads, ff_dim, rate =0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.transformer_layers = [TransformerBlock(embed_dim,\n",
    "                                                    num_heads,\n",
    "                                                    rate = rate,\n",
    "                                                    ff_dim = ff_dim) for _ in range(num_layers)]\n",
    "    def call(self, x):\n",
    "        inputs = x\n",
    "        for layer in self.transformer_layers:\n",
    "            out = layer(inputs)\n",
    "            inputs = out \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd979b41-5454-45ba-a724-853c2ee927ce",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1654212626690,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "bd979b41-5454-45ba-a724-853c2ee927ce"
   },
   "outputs": [],
   "source": [
    "class Decoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_layers, num_heads, ff_dim, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.ff_dim = ff_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(num_heads=num_heads,\n",
    "                                                     key_dim=embed_dim)\n",
    "        self.attention_2 = layers.MultiHeadAttention(num_heads=num_heads,\n",
    "                                                     key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential([layers.Dense(ff_dim, activation=\"relu\"),\n",
    "                                            layers.Dense(embed_dim),])\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat([tf.expand_dims(batch_size, -1), \n",
    "                          tf.constant([1, 1], dtype=tf.int32)],\n",
    "                          axis=0,)\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        for _ in range(num_layers):\n",
    "            casual_mask = self.get_causal_attention_mask(inputs)\n",
    "            \n",
    "            if mask is not None:\n",
    "                padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "                padding_mask = tf.minimum(padding_mask, casual_mask)\n",
    "            \n",
    "            else:\n",
    "                padding_mask = None\n",
    "            attention_output_1 = self.attention_1(query = inputs,\n",
    "                                                  value = inputs,\n",
    "                                                  key = inputs, \n",
    "                                                  attention_mask=casual_mask)\n",
    "            \n",
    "            out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "\n",
    "            attention_output_2 = self.attention_2(query = out_1,\n",
    "                                                  value = encoder_outputs,\n",
    "                                                  key = encoder_outputs,\n",
    "                                                  attention_mask = padding_mask,)\n",
    "            \n",
    "            out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "            proj_output = self.dense_proj(out_2)\n",
    "            out = self.layernorm_3(out_2 + proj_output)\n",
    "            inputs = out\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ae51dd4-0b79-4b9d-9352-5d284ee8f78c",
   "metadata": {
    "executionInfo": {
     "elapsed": 5745,
     "status": "ok",
     "timestamp": 1654212632431,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "2ae51dd4-0b79-4b9d-9352-5d284ee8f78c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataset = pd.read_csv('eng-spa.txt', sep='\\t', header=None)\n",
    "dataset = dataset.iloc[:,0:2]\n",
    "\n",
    "source_tokens = []\n",
    "for sentence in dataset.iloc[:,0]:\n",
    "    source_tokens.append(sentence.lower().split(' '))\n",
    "\n",
    "target_tokens = []\n",
    "for sentence in dataset.iloc[:,1]:\n",
    "    target_tokens.append(sentence.lower().split(' '))\n",
    "    \n",
    "def build_token_dict(token_list):\n",
    "    token_dict = {'<TOKEN_NULO>': 0,'<TOKEN_INICIO>': 1,'<TOKEN_FIN>': 2}\n",
    "    for tokens in token_list:\n",
    "        for token in tokens:\n",
    "            if token not in token_dict:\n",
    "                token_dict[token] = len(token_dict)\n",
    "    return token_dict\n",
    "\n",
    "\n",
    "source_token_dict = build_token_dict(source_tokens)\n",
    "target_token_dict = build_token_dict(target_tokens)\n",
    "\n",
    "\n",
    "# DICCIONARIO PARA LA TRADUCCIÓN (para programa que genera la traducción): de número a token\n",
    "target_token_dict_inv = {v:k for k,v in target_token_dict.items()}\n",
    "source_token_dict_inv = {v:k for k,v in source_token_dict.items()}\n",
    "\n",
    "# Agregar inicio, fin y vacío a cada frase\n",
    "# Corpus Inglés + inicio-fin\n",
    "encoder_tokens = [['<TOKEN_INICIO>'] + tokens + ['<TOKEN_FIN>'] for tokens in source_tokens]\n",
    "# Corpus Español + inicio-fin\n",
    "decoder_tokens = [['<TOKEN_INICIO>'] + tokens + ['<TOKEN_FIN>'] for tokens in target_tokens]\n",
    "# Corpus como debería ser la salida + fin (para la salida del modelo)\n",
    "output_tokens = [tokens + ['<TOKEN_FIN>'] for tokens in target_tokens]\n",
    "\n",
    "source_max_len = max(map(len, encoder_tokens))\n",
    "target_max_len = max(map(len, decoder_tokens))\n",
    "\n",
    "max_len = max(source_max_len,target_max_len)\n",
    "\n",
    "encoder_tokens = [tokens + ['<TOKEN_NULO>']*(max_len-len(tokens)) for tokens in encoder_tokens]\n",
    "decoder_tokens = [tokens + ['<TOKEN_NULO>']*(max_len-len(tokens)) for tokens in decoder_tokens]\n",
    "output_tokens = [tokens + ['<TOKEN_NULO>']*(max_len-len(tokens)) for tokens in output_tokens ]\n",
    "\n",
    "encoder_input = [list(map(lambda x: source_token_dict[x], tokens)) for tokens in encoder_tokens]\n",
    "decoder_input = [list(map(lambda x: target_token_dict[x], tokens)) for tokens in decoder_tokens]\n",
    "output_decoder = [list(map(lambda x: target_token_dict[x], tokens)) for tokens in output_tokens]\n",
    "\n",
    "# ENTRADAS\n",
    "x1 = np.array(encoder_input)#astype('float32')\n",
    "x2 = np.array(decoder_input)#.astype('float32')\n",
    "\n",
    "# SALIDA\n",
    "y = np.array(output_decoder)#.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78670f10-0e4a-41bf-b2b8-8e297ad982f2",
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1654212632432,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "78670f10-0e4a-41bf-b2b8-8e297ad982f2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "z = [1, 2, 3, 4, 5]\n",
    "x = [2, 4, 6, 8, 10]\n",
    "yp = [-3, 1, -2, -1, 0]\n",
    "ztr, zte, yt1, yte1 = train_test_split(z, yp, random_state=73)\n",
    "xtr, xte, yt2, yte2 = train_test_split(x, yp, random_state=73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7892be2-d5fb-4b12-a8ee-0b8abd7a61b5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1654212632433,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "f7892be2-d5fb-4b12-a8ee-0b8abd7a61b5",
    "outputId": "d1dc9845-9e39-4387-ef34-a2fc1feb722c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt1 == yt2, yte1 == yte2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31043624-6a7d-4fec-b1ab-b05d489f767d",
   "metadata": {
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1654212632803,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "31043624-6a7d-4fec-b1ab-b05d489f767d"
   },
   "outputs": [],
   "source": [
    "x1_train, x1_test, y_train, y_test = train_test_split(x1, y, train_size = 0.7, random_state = 73)\n",
    "x2_train, x2_test, y_train, y_test = train_test_split(x2, y, train_size = 0.7, random_state = 73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af5d0b18-3587-4b64-9386-c44d4ae73746",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1654212632804,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "af5d0b18-3587-4b64-9386-c44d4ae73746",
    "outputId": "dc1e6b28-3a5b-4906-91db-04ac733cd7da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29638"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2dc92dca-e9c3-4099-b628-8aab400968a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3509,
     "status": "ok",
     "timestamp": 1654213551035,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "2dc92dca-e9c3-4099-b628-8aab400968a7",
    "outputId": "b29ed410-2753-4c49-91fc-7914c8f88a57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, 17)]         0           []                               \n",
      "                                                                                                  \n",
      " token_and_position_embedding_4  (None, 17, 256)     4273664     ['encoder_inputs[0][0]']         \n",
      "  (TokenAndPositionEmbedding)                                                                     \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, 17)]         0           []                               \n",
      "                                                                                                  \n",
      " encoder_2 (Encoder)            (None, 17, 256)      5262336     ['token_and_position_embedding_4[\n",
      "                                                                 0][0]']                          \n",
      "                                                                                                  \n",
      " model_4 (Functional)           (None, 17, 29638)    17313734    ['decoder_inputs[0][0]',         \n",
      "                                                                  'encoder_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 26,849,734\n",
      "Trainable params: 26,849,734\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#HYPERMARAMETERS\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "embed_dim = 256\n",
    "num_layers = 4\n",
    "num_heads = 3\n",
    "ff_dim = 1024\n",
    "\n",
    "\n",
    "source_vocab_size = len(source_token_dict)\n",
    "target_vocab_size = len(target_token_dict)\n",
    "encoder_input = decoder_input = max_len\n",
    "\n",
    "#MODEL\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(max_len, ), dtype=\"int32\", name=\"encoder_inputs\")\n",
    "\n",
    "x = TokenAndPositionEmbedding(max_len, source_vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = Encoder(embed_dim = embed_dim,\n",
    "                          num_layers = num_layers,\n",
    "                          num_heads = num_heads,\n",
    "                          ff_dim = ff_dim\n",
    "                          )(x)\n",
    "\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(max_len,), dtype=\"int32\", name=\"decoder_inputs\")\n",
    "\n",
    "encoded_seq_inputs = keras.Input(shape=(max_len, embed_dim, ), dtype=\"float32\",name=\"decoder_state_inputs\")\n",
    "\n",
    "x = TokenAndPositionEmbedding(max_len, target_vocab_size, embed_dim)(decoder_inputs)\n",
    "x = Decoder(embed_dim = embed_dim, \n",
    "            num_layers = num_layers,\n",
    "            num_heads = num_heads, \n",
    "            ff_dim = ff_dim\n",
    "            )(x, encoded_seq_inputs)\n",
    "\n",
    "x = layers.Dropout(0.1)(x)\n",
    "\n",
    "decoder_outputs = layers.Dense(target_vocab_size, activation=\"softmax\")(x)\n",
    "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "\n",
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "\n",
    "transformer = keras.Model(inputs = [encoder_inputs, decoder_inputs], \n",
    "                          outputs = decoder_outputs,\n",
    "                          name = \"transformer\")\n",
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "909efb34-1f0e-42e4-8ead-87610bb82cd3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 697356,
     "status": "ok",
     "timestamp": 1654213336044,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "909efb34-1f0e-42e4-8ead-87610bb82cd3",
    "outputId": "812e01fd-81de-4cac-9816-786f5cba7f5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "922/922 [==============================] - 147s 143ms/step - loss: 2.9103 - accuracy: 0.7110 - val_loss: 1.7537 - val_accuracy: 0.7664 - lr: 1.0000e-04\n",
      "Epoch 2/5\n",
      "922/922 [==============================] - 129s 140ms/step - loss: 1.5259 - accuracy: 0.7898 - val_loss: 1.3921 - val_accuracy: 0.8078 - lr: 1.0000e-04\n",
      "Epoch 3/5\n",
      "922/922 [==============================] - 130s 141ms/step - loss: 1.2306 - accuracy: 0.8220 - val_loss: 1.2031 - val_accuracy: 0.8283 - lr: 1.0000e-04\n",
      "Epoch 4/5\n",
      "922/922 [==============================] - 129s 140ms/step - loss: 1.0310 - accuracy: 0.8456 - val_loss: 1.0741 - val_accuracy: 0.8465 - lr: 1.0000e-04\n",
      "Epoch 5/5\n",
      "922/922 [==============================] - 129s 140ms/step - loss: 0.8769 - accuracy: 0.8658 - val_loss: 0.9863 - val_accuracy: 0.8585 - lr: 1.0000e-04\n",
      "CPU times: user 6min 41s, sys: 26.4 s, total: 7min 8s\n",
      "Wall time: 11min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "\n",
    "def step_decay(epoch):\n",
    "   lrate = 1e-4\n",
    "   return lrate\n",
    "\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate = CustomSchedule(embed_dim, 1e-2),\n",
    "#                                      name='Adam')\n",
    "callbacks = [LearningRateScheduler(step_decay)]\n",
    "transformer.compile(optimizer=\"adam\",\n",
    "                    loss=\"sparse_categorical_crossentropy\", \n",
    "                    metrics=[\"accuracy\"])\n",
    "\n",
    "history = transformer.fit([x1_train, x2_train], y_train, \n",
    "                          batch_size = batch_size, \n",
    "                          epochs = epochs, \n",
    "                          validation_data = [[x1_test, x2_test], y_test],\n",
    "                          callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ptPdccA1lgV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1654213336045,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "4ptPdccA1lgV",
    "outputId": "f497794a-8b7d-4af3-eeaa-295e88928ca2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f4ef67e4210>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhV5bX48e/KDGSCJAwZIMwQZojIoIKziNXaQmuvU6fLRW3VWutUx6q/emurVm2vem+tVq1aUVsLKGrFoTJogiBDABkCJAQSQhICCSHD+v2xd8IhnpAEcs7OsD7Pc56cs/e7917nQLLOO+z3FVXFGGOMaSzE6wCMMca0T5YgjDHG+GUJwhhjjF+WIIwxxvhlCcIYY4xfliCMMcb4ZQnCmAARkT4i8rGIlIvI77yOx5jWCvM6AGMCQUQO+rzsDlQBte7r/1LVl4IQxjxgHxCrdsOR6YAsQZhOSVWj65+LSC7wY1V9v3E5EQlT1ZoAhTEA2HAiySHAcQX8/KZzsCYm06WIyEwRyRORW0VkD/BnEekpIgtFpEhEStznqT7HfCgi94vIp25z0bsikujuixKRF0WkWERKReRzt2npOeBq4BYROSgi54hIpIg8JiK73cdjIhJ5nLjuFZHX3POXi8haERkmIreLSKGI7BKR83zijBORP4lIgYjki8gDIhLq7vu+G/+jIlIM3Bu0D910WJYgTFfUF+iF8w1/Hs7vwZ/d1/2BSuDJRsf8B/ADoDcQAdzsbr8aiAPSgARgPlCpqt8HXgJ+o6rRbu3ll8AUYDwwDpgM3HmcuAC+AbwA9AS+AJa48aYAvwKe9jn+OaAGGAJMAM4Dfuyz/1RgG9AHeLDZT8l0eZYgTFdUB9yjqlWqWqmqxar6uqpWqGo5zh/PGY2O+bOqblbVSuBvOH/kAapxEsMQVa1V1WxVPdDEdS8HfqWqhapaBNwHXNlUXO62T1R1idsc9BqQBDykqtXAK0C6iMSLSB/gQuBGVT2kqoXAo8BlPuffrapPqGqNz/mNaZL1QZiuqEhVD9e/EJHuOH9ML8D5pg4QIyKhqlrfsb3H5/gKoL6P4wWc2sMrIhIPvAj80v0D3lgysMPn9Q53m9+4XHt9nlcC+3xiqv8jH+2eJxwoEJH68iHALp/jfZ8b0yyrQZiuqHGn8c+B4cCpqhoLnOFuF5qhqtWqep+qZgDTgIuAq5oovhun+ahef3dbU3G1xi6ckVqJqhrvPmJVdVQbnd90QZYgjIEYnG/jpSLSC7inpQeKyJkiMsbtDD6A0+RU10Txl4E7RSTJ7eS+G6fGcdJUtQB4F/idiMSKSIiIDBaRxk1lxrSYJQhj4DGgG849CyuAd1pxbF9gAU5yyAE+wml28ucBIAv4ElgLrHK3tZWrcDrQNwAlblz92vD8posRu3/HGGOMP1aDMMYY45clCGOMMX4FLEG4d5h+JiJrRGS9iNznp0ykiLwqIltEZKWIpPvsu93dvklEzg9UnMYYY/wLZA2iCjhLVcfh3FR0gYhMaVTmR0CJqg7BGYf+3wAikoFzg88onLHpf6yfMsAYY0xwBOxGOXeCsvoZNcPdR+Me8Us4OifMAuBJce7yuQR4RVWrgO0isgVnWoLlx7tmYmKipqent0n8xhjTFWRnZ+9T1SR/+wJ6J7X7rT8bZ26YP6jqykZFUnDv7lTVGhEpw5m2IAVnuGG9PHfbcaWnp5OVldUWoRtjTJcgIjua2hfQTmp3bprxQCowWURGt/U1RGSeiGSJSFZRUVFbn94YY7qsoIxiUtVSYClOf4KvfJx5bBCRMJxZMYt9t7tS3W3+zv2MqmaqamZSkt9akjHGmBMQyFFMSe7kZYhIN+BcYGOjYm/hTJcMMAf4wO27eAu4zB3lNBAYCnwWqFiNMcZ8XSD7IPoBz7v9ECHA31R1oYj8CshS1beAPwEvuJ3Q+3GnJlbV9SLyN5wpA2qA63xmsDTGdAHV1dXk5eVx+HDjCW7NiYiKiiI1NZXw8PAWH9OpptrIzMxU66Q2pnPYvn07MTExJCQk4DOFuTkBqkpxcTHl5eUMHDjwmH0ikq2qmf6OszupjTHt0uHDhy05tBERISEhodW1MUsQxph2y5JD2zmRz7LLJ4iqmlqe+XgrWbn7vQ7FGGPalS6fIGrrlGf/nct9/9xAXV3n6Y8xxpy86Ojo5gudoOLiYsaPH8/48ePp27cvKSkpDa+PHDnS7PFZWVlcf/31AYsPbE1qukeEccsFw7npb2v4++p8vjUx1euQjDFdQEJCAqtXrwbg3nvvJTo6mptvvvmYMjU1NYSF+f8znZmZSWam377lNtPlaxAA3xyfwtjUOH7zziYqjtR4HY4xph1bvXo1U6ZMYezYsVx66aWUlJQA8Pjjj5ORkcHYsWO57LLLAPjoo48aagUTJkygvLy82fN///vfZ/78+Zx66qnccsstfPbZZ0ydOpUJEyYwbdo0Nm3aBMCHH37IRRddBDgJ5oc//CEzZ85k0KBBPP74423yXrt8DQIgJES4c3YG33l6Oc98vI0bzxnmdUjGGB/3/XM9G3YfaNNzZiTHcs83RrX6uKuuuoonnniCGTNmcPfdd3Pffffx2GOP8dBDD7F9+3YiIyMpLS0F4Le//S1/+MMfmD59OgcPHiQqKqpF18jLy2PZsmWEhoZy4MABPvnkE8LCwnj//fe54447eP311792zMaNG1m6dCnl5eUMHz6ca665plX3PPhjNQjX5IG9uHBMX57+aBt7yuzGHGPM15WVlVFaWsqMGTMAuPrqq/n4448BGDt2LJdffjkvvvhiQ7PQ9OnTuemmm3j88ccpLS1tsrmosblz5xIaGtpwzblz5zJ69Gh+9rOfsX79er/HzJ49m8jISBITE+nduzd79+492bdrNQhft10wkvc3FPLwkk387jvjvA7HGOM6kW/6wbZo0SI+/vhj/vnPf/Lggw+ydu1abrvtNmbPns3ixYuZPn06S5YsYcSIEc2eq0ePHg3P77rrLs4880zefPNNcnNzmTlzpt9jIiMjG56HhoZSU3PyzeVWg/DRP6E7PzgtnddX5bE2r8zrcIwx7UxcXBw9e/bkk08+AeCFF15gxowZ1NXVsWvXLs4880z++7//m7KyMg4ePMjWrVsZM2YMt956K6eccgobNzaejq55ZWVlpKQ4qx0899xzbfl2mmUJopHrzhxCQo8I7l+4gc40DYkxpvUqKipITU1teDzyyCM8//zz/OIXv2Ds2LGsXr2au+++m9raWq644grGjBnDhAkTuP7664mPj+exxx5j9OjRjB07lvDwcGbNmtXqGG655RZuv/12JkyY0Ca1gtawuZj8eHHFDu78+zr+5/KJzBrTrw0iM8a0Vk5ODiNHjvQ6jE7F32dqczG10mWnpDGsTzS/fnsjVTU2iawxpmuyBOFHWGgId87OYOf+Cp5flut1OMYY4wlLEE04Y1gSM4cn8cS/tlB8sMrrcIwxJugsQRzHnbNHUlFdy6Pvb/Y6FGOMCbpALjmaJiJLRWSDiKwXkRv8lPmFiKx2H+tEpFZEern7ckVkrbvPk1WAhvSO4fJT+/PXlTvZvLf5W+SNMaYzCWQNogb4uapmAFOA60Qkw7eAqj6squNVdTxwO/CRqvrOu32muz+wM1Idx43nDKNHZBgPLsrxKgRjjPFEwBKEqhao6ir3eTmQA6Qc55DvAS8HKp4T1atHBNefNZSPNhfx4aZCr8MxxgRRe57uG5wJ+5YtWxawGIPSByEi6cAEYGUT+7sDFwC+M1Ap8K6IZIvIvOOce56IZIlIVlFRUdsF7eOqaQMYkNCdBxflUFNbF5BrGGO6lvrpvlevXs38+fP52c9+1vA6IiKiRefo8AlCRKJx/vDfqKpNTcf4DeDTRs1Lp6nqRGAWTvPUGf4OVNVnVDVTVTOTkpLaNPZ6kWGh3D5rJF8VHuTlz3cF5BrGmI4h0NN9Z2dnM2PGDCZNmsT5559PQUGB3/Pn5uby1FNP8eijjzJ+/PiG6T/aUkAn6xORcJzk8JKqvnGcopfRqHlJVfPdn4Ui8iYwGfg4ULE25/xRfTh1YC8efW8zF49LJq7byU2ja4xphbdvgz1r2/acfcfArIdafVggp/uurq7mpz/9Kf/4xz9ISkri1Vdf5Ze//CXPPvvs184fHx/P/Pnz/S401FYCOYpJgD8BOar6yHHKxQEzgH/4bOshIjH1z4HzgHWBirUlRIS7LsqgpOIIf1i6xctQjDEeCfR035s2bWLdunWce+65jB8/ngceeIC8vLwmzx9ogbzKdOBKYK2IrHa33QH0B1DVp9xtlwLvquohn2P7AG86OYYw4K+q+k4AY22R0SlxfHtiKs99msvlp/ZnQEKP5g8yxpy8E/imH2xtMd23qjJq1CiWL1/eovMHWiBHMf1bVUVVx9YPZVXVxar6lE9yQFWfU9XLGh27TVXHuY9RqvpgoOJsrV+cP5zQEOGht1s/ba8xpmML9HTfw4cPp6ioqCFBVFdXs379+ibPHxMT06J+jRNlCwa1Up/YKObPGMyj729m5bZiTh2U4HVIxpgAqZ/uu95NN93E888/z/z586moqGDQoEH8+c9/bpjuu6ysDFVtmO77rrvuYunSpYSEhDBq1Khmp/uOiIhgwYIFXH/99ZSVlVFTU8ONN97IsGHD/J7/G9/4BnPmzOEf//gHTzzxBKeffnqbvn+b7vsEVB6p5azffUhidCT/uG46ISES8Gsa09XYdN9tz6b7DoJuEaHccsFw1uaX8eYX+V6HY4wxAWEJ4gRdMi6Fcalx/GbJRiqOBHeVJ2OMCQZLECcoJES486IM9h6o4umPtnkdjjGdUmdqAvfaiXyWliBOwinpvZg9ph9Pf7yVgrJKr8MxplOJioqiuLjYkkQbUFWKi4ubvVGvMRvFdJJumzWC9zbs5eElm3jkO+O9DseYTiM1NZW8vDwCNcdaVxMVFXXMiKyWsARxktJ6deeHpw3kqY+28v1p6YxNjfc6JGM6hfDwcAYOHOh1GF2aNTG1gevOHExCjwjuX7jBqsPGmE7DEkQbiIkK56bzhvF5bglvr9vjdTjGGNMmLEG0ke9mpjG8Twy/fjuHqppar8MxxpiTZgmijYSFhnDnRSPZtb+S5z7N9TocY4w5aZYg2tDpQ5M4c3gST36whX0Hq7wOxxhjTooliDb2y9kjqaiu5dH3NnsdijHGnBRLEG1sSO8Yrji1Py9/tpPNewM3Da8xxgRaIFeUSxORpSKyQUTWi8gNfsrMFJEyEVntPu722XeBiGwSkS0iclug4gyEG88ZRnRkGA8syvE6FGOMOWGBrEHUAD9X1QxgCnCdiGT4KfeJz4JCvwIQkVDgD8AsIAP4XhPHtks9e0Rw/dlD+XhzEUs3FXodjjHGnJBArihXoKqr3OflQA6Q0sLDJwNb3JXljgCvAJcEJtLAuGpqOukJ3XlwUQ7VtXVeh2OMMa0WlD4IEUkHJgAr/eyeKiJrRORtERnlbksBdvmUyaOJ5CIi80QkS0Sy2tOcLRFhIdx+4Ui2FB7klc92eh2OMca0WsAThIhEA68DN6rqgUa7VwEDVHUc8ATw99aeX1WfUdVMVc1MSko6+YDb0HkZfZgyqBePvLeZsspqr8MxxphWCWiCEJFwnOTwkqq+0Xi/qh5Q1YPu88VAuIgkAvlAmk/RVHdbhyIi3Dk7g9LKap784CuvwzHGmFYJ5CgmAf4E5KjqI02U6euWQ0Qmu/EUA58DQ0VkoIhEAJcBbwUq1kAanRLHnImpPLcslx3Fh7wOxxhjWiyQNYjpwJXAWT7DWC8UkfkiMt8tMwdYJyJrgMeBy9RRA/wEWILTuf03VV0fwFgD6hfnDyc8NIRfL97odSjGGNNiAVsPQlX/DUgzZZ4Enmxi32JgcQBCC7resVFcM2Mwv3tvMyu2FTNlUILXIRljTLPsTuog+fHpg+gXF8UDizZQV2drRhhj2j9LEEHSLSKUWy8Ywbr8A7zxRYfrbzfGdEGWIILo4nHJjEuL5+ElG6k4UuN1OMYYc1yWIIIoJES4a/ZI9h6o4qmPtnkdjjHGHJcliCDLTO/F7LH9eObjrRSUVXodjjHGNMkShAduu2AEdQoPv7PJ61CMMaZJliA8kNarOz86bSBvfJHPml2lXodjjDF+WYLwyLUzB5MYHcH9CzegasNejTHtjyUIj8REhXPTucPJ2lHC4rV7vA7HGGO+xhKEh757Shoj+sbw0Ds5HK6u9TocY4w5hiUID4WGOLO97tpfyXPLcr0OxxhjjmEJwmOnDU3krBG9efKDLew7WOV1OMYY08ASRDtwx4UjOVxdyyPvbfY6FGOMaWAJoh0Y0juaK6YM4JXPdrJpT7nX4RhjDGAJot244eyhREeG8cAiG/ZqjGkfArmiXJqILBWRDSKyXkRu8FPmchH5UkTWisgyERnnsy/X3b5aRLICFWd70bNHBNefPZRPvtrHh5uKvA7HGGMCWoOoAX6uqhnAFOA6EcloVGY7MENVxwD3A8802n+mqo5X1cwAxtluXDU1nYGJPXhg0Qaqa+u8DscY08UFLEGoaoGqrnKfl+MsHZrSqMwyVS1xX64AUgMVT0cQERbC7bNGsLXoEC9/ttPrcIwxXVxQ+iBEJB2YAKw8TrEfAW/7vFbgXRHJFpF5xzn3PBHJEpGsoqKO3zRzbkYfpg5K4NH3NlNWUe11OMaYLizgCUJEooHXgRtV9UATZc7ESRC3+mw+TVUnArNwmqfO8Hesqj6jqpmqmpmUlNTG0QefiHDnRSMprazmiQ++8jocY0wXFtAEISLhOMnhJVV9o4kyY4H/Ay5R1eL67aqa7/4sBN4EJgcy1vZkVHIccyel8vzyXHL3HfI6HGNMFxXIUUwC/AnIUdVHmijTH3gDuFJVN/ts7yEiMfXPgfOAdYGKtT26+bzhhIeG8Ou3c7wOxRjTRYUF8NzTgSuBtSKy2t12B9AfQFWfAu4GEoA/OvmEGnfEUh/gTXdbGPBXVX0ngLG2O71jo7h25mB+++5mlm8tZurgBK9DMsZ0MdKZbsrKzMzUrKzOc8vE4epazvrth/TsEcFbPzmN0BDxOiRjTCcjItlN3Upgd1K3Y1Hhodw6awTrdx/gjVV5XodjjOliLEG0cxePS2Z8WjwPL9nEoaoar8MxxnQhliDaORHhrosyKCyv4umPtnodjjGmC7EE0QFMGtCTi8b245lPtrG7tNLrcIwxXYQliA7itlkjqFN4eMkmr0MxxnQRliA6iNSe3fnxaQN584t8Vu8q9TocY0wXYAmiA7lm5mASoyN4YKGtGWGMCTxLEB1ITFQ4Pz9vOFk7Sli0tsDrcIwxnZwliA7mO5lpjOgbw0Nvb+Rwda3X4RhjOjFLEB1MaIhw5+wM8koq+fOnuV6HY4zpxCxBdECnDU3k7BG9+cPSLRSVV3kdjjGmk2pRghCR34hIrIiEi8i/RKRIRK4IdHCmaXfMHsnh6loefX9z84WNMeYEtLQGcZ672M9FQC4wBPhFoIIyzRucFM0VUwbwymc72bjH7zpMxhhzUlqaIOqnBZ8NvKaqZQGKx7TCjecMJSYqnAcX5diwV2NMm2tpglgoIhuBScC/RCQJOBy4sExLxHeP4Pqzh/LJV/tYuqnQ63CMMZ1MixKEqt4GTAMyVbUaOARcEsjATMtcOWUAAxN78OCiHKpr67wOxxjTibRmFFMy8G0RuQqYg7MMaJNEJE1ElorIBhFZLyI3+CkjIvK4iGwRkS9FZKLPvqtF5Cv3cXUr4uxSIsJCuOPCkWwtOsRfV+70OhxjTCfS0lFM9wBPuI8zgd8AFzdzWA3wc1XNAKYA14lIRqMys4Ch7mMe8D/u9XoB9wCnApOBe0SkZ0ti7YrOGdmbaYMTePT9zZRVVHsdjjGmk2hpDWIOcDawR1V/AIwD4o53gKoWqOoq93k5kAOkNCp2CfAXdawA4kWkH3A+8J6q7lfVEuA94IKWvqmuRkT45eyRlFVW8/gHX3kdjjGmk2hpgqhU1TqgRkRigUIgraUXEZF0YAKwstGuFGCXz+s8d1tT2/2de56IZIlIVlFRUUtD6nRGJcfxnUlp/GV5Ltv3HfI6HGNMJ9DSBJElIvHA/wLZwCpgeUsOFJFo4HXgRvdeijalqs+oaqaqZiYlJbX16TuUn58/jIjQEH69OMfrUIwxnUBLRzFdq6qlqvoUcC5wtdvUdFwiEo6THF5S1Tf8FMnn2JpIqrutqe3mOHrHRHHtmUN4d8Nelm3d53U4xpgOrqWd1JeKSByAquYCO0Xkm80cI8CfgBxVfaSJYm8BV7mjmaYAZapaACwBzhORnm7n9HnuNtOMH502kJT4bjywMIfaOrt5zhhz4lraxHSP793TqlqKM8roeKYDVwJnichq93GhiMwXkflumcXANmALTvPVte759wP3A5+7j1+520wzosJDueWC4WwoOMDrq/K8DscY04GFNV8E8J9Ijnusqv4bkGbKKHBdE/ueBZ5tYXzGx8XjknluWS4PL9nE7DH96BHZ0n9mY4w5qjWd1I+IyGD38QhOZ7Vph0SEuy7KoKi8iqc+2up1OMaYDqqlCeKnwBHgVfdRRRPf/E37MLF/T74xLplnPt5Gfmml1+EYYzqglo5iOqSqt9UPJ1XV21XVBtu3c7deMByAh9/Z6HEkxpiO6LgJQkQec3/+U0TeavwITojmRKX27M6PTx/I31fvZvWuUq/DMcZ0MM31Xr7g/vxtoAMxgXHNzCG8+nke9y/cwIL5U3FGHxtjTPOOW4NQ1WwRCQXmqepHjR9BitGchOjIMG4+bxjZO0pY+GWB1+EYYzqQZvsgVLUWGCAiEUGIxwTA3Mw0RvaL5aG3N3K4utbrcIwxHURLRzFtAz4VkbtE5Kb6RyADM20nNES4a/ZI8ksrefbT7V6HY4zpIFqaILYCC93yMe4jOlBBmbY3bUgi54zswx+XbqWovMrrcIwxHUBLE8QGVb3P94GzvoPpQO64cASHq2t55L3NXodijOkAWpogbm/hNtOODUqK5sqpA3j1851s3NPmM68bYzqZ5u6DmCUiTwAp7trR9Y/ncJYUNR3MDWcPJSYqnAcW5uBMhWWMMf41V4PYDWQBh3HmXqp/vIWzLKjpYOK7R3DD2UP595Z9fLCx0OtwjDHtWHMzsq4B1ojIX92y/VV1U1AiMwFz5dQBvLhiBw8uzuGMYUmEh7a0pdEY05U0+ZehfoEg1wXAauAdd994m2qj4woPDeGOC0eyregQL63Y4XU4xph26nhfHb8rInPc5/cCk4FSAFVdDQw83olF5FkRKRSRdU3s/4XPQkLrRKRWRHq5+3JFZK27L6u1b8o07+yRvZk+JIHH/vUVZRXVXodjjGmHmkwQqvoMMNJ9We27olx9kWbO/RxOzaOp8z+squNVdTzOiKiPGq0ad6a7P7OZ65y8klzoYh22IsIvL8ygrLKa3//rK6/DMca0Q83NxXS/+3S9iPwHECoiQ92RTcuaOfZjoKXLhH4PeLmFZdvWkQr437Pgf6bDmlehtut8m85IjuW7mWn8ZXku24oOeh2OMaadac2CQaNwFgp6GTgA3NgWAYhId5yaxus+mxV4V0SyRWReM8fPE5EsEckqKipqfQCh4XDeA6C18OY8+P14WP5HqOoafzBvOm8YkWEh/PptWzPCGHMsCeRYeBFJBxaq6ujjlPkucIWqfsNnW4qq5otIb+A94KdujeS4MjMzNSvrBLss6upgy3vw78dg5zKIiofJ/wmT/wuik07snB3EH5Zu4eElm/jrf57KtMGJXodjjAkiEcluqin/uAmiuZFKqnpxMxdOp/kE8Sbwmqr+tYn99wIHVbXZNSlOKkH42vUZfPp72LgIwiJh/OUw7SfQa9DJn7sdOlxdy9m/+4jYbuEs/OlphIbYmhHGdBXHSxDNLRg0FdiF06y0EmjTvxzuUNoZwBU+23oAIapa7j4/D/hVW163WWmT4bKXYN9XsOxx+OIFyP4zjLwYpt8AKRODGk6gRYWHcuusEVz/8he8np3Hd05J8zokY0w70FwfRF/gDmA08HvgXGBfSxYMEpGXgeXAcBHJE5Efich8EZnvU+xS4N1G61v3Af4tImuAz4BFqvpO695WG0kcChc/ATeuhWnXw9YP4H/PhOe/AVve71Qjn74xth8T+8fz8LubOFhls6gYY1rRByEikTijjR4G7lPVJwMZ2Ilosyamphw+ANnPwYo/QnkB9Bnt1ChGXep0dndwq3aW8K0/LuMnZw7h5vOHex2OMSYIjtfE1OwoJhGJFJFvAS8C1wGPA2+2bYgdRFQsTL8ebvgSLvmjMyT2jf+ExyfCiqfgyKHmz9GOTezfk4vHJfO/n2wjv7TS63CMMR5rbjbXv+A0E03EqTWcoqr3q2p+UKJrr8IiYMLlcO0K+N4rEJcC79wKj46CDx6EQ/u8jvCE3TprBAC/eceGvRrT1TU3iqkOqP9a7FtQAFXV2ADG1moBb2I6np0rnZFPmxZBWBRMuAKm/gR6HXdGknbpt0s28eTSLbx57TQm9O/pdTjGmAA64WGuHY2nCaJe0WZn5NOaV5yb7zK+6TRLJU/wNq5WOFRVw8zffkhaz268fs00RGzYqzGd1Un1QZhWShoGlzzpjnz6qTPa6ZmZ8PzFziioDpCQe0SGcfN5w1i1s5SFXxZ4HY4xxiOWIAIlth+c+yv42TrnZ9EmeOFSePp0WLsAatv3UNI5k9LI6BfLQ29v5HB1rdfhGGM8YAki0KLinKGwN34JFz8JNVXw+o/giQmw8ul2O/IpNES486KR5JdW8qd/b/c6HGOMByxBBEtYJEy8Eq5dCZe9DDH94O1b4NHRsPTXcKjY6wi/ZtrgRM7N6MMfl26hsPyw1+EYY4LMEkSwhYTAiAvhR+/CD5dA/ynw0UPOENlFNztrU7Qjt88aQVVNHY++t9nrUIwxQWYJwkv9p8D3XobrPoPR33bu0n58Aiz4IRSs8To6AAYlRXPV1HRe/XwXOQUHvA7HGBNEliDag6Th8M0/OP0UU38Cm9+Fp8+Av3wTti71fOTTDWcPJbZbOA8s2kBnGhZtjDk+SxDtSWwynHc/3F0fFkQAABpYSURBVLQezrkPCnPghW86ycLDkU9x3cO58eyhfLqlmH/lFHoSgzEm+CxBtEdRcXDaje7IpyegutId+TQRPvtfZ5nUILt8ygAGJfXg/y3Oobq2LujXN8YEnyWI9iwsEiZe5fRRfPcliO4Ni2+Gx0bDh/8NFS1d8vvkhYeG8MsLR7Jt3yFeXLEjaNc1xnjHEkRHEBICIy+CH70HP3gHUifDh//PGfm0+BYoCc4f7LNG9Oa0IYk89v5XlFYcCco1jTHeCViCEJFnRaRQRNY1sX+miJSJyGr3cbfPvgtEZJOIbBGR2wIVY4cjAgOmwn+84swkO+pSyHrWHfn0Iyj4MsCXF345eyTlh6u5+tnPWJCdR8WR9n1HuDHmxAVssj4ROQM4CPzF35rUIjITuFlVL2q0PRTYjLN6XR7wOfA9Vd3Q3DXbxWR9wVaWDyv/B7KegyPlMPgs587tgTOchBIAf8vaxR+XbiG3uIIeEaFcOKYfczPTOCW9p03sZ0wH49lsriKSDixsZYKYCtyrque7r28HUNVfN3e9Lpkg6lWWOrWJFf8Dhwqh33gnUYy8GEKbW3q89VSVrB0lvJa1i0VfFnDoSC0DErozZ2Iq35qUSkp8tza/pjGm7bXnBPE6Ti1hN06yWC8ic4ALVPXHbrkrgVNV9SdNXGMeMA+gf//+k3bs6OIdqNWH4ctXnSnHi7dAz3Tn3ooJV0B4YP5oVxyp4e21e3gtexcrtu1HBKYPTmRuZirnj+pLVHhoQK5rjDl57TVBxAJ1qnpQRC4Efq+qQ1ubIHx16RpEY3W1sGkx/PsxyM+C7olw6n/BKT+G7r0Cdtld+ytYkJ3Hguw88ksriYkM46JxyczNTGVCWrw1QRnTzrTLBOGnbC6QCQzFmpjajirsWOasdvfVEgjvDhOvhqnXQnz/gF22rk5Zsb2YBVl5LF5XwOHqOgYn9WDOpDS+NTGFPrFRAbu2Mabl2mWCEJG+wF5VVRGZDCwABgD1ndRnA/k4ndT/oarrm7ueJYhm7N0Ay56AtX9zEsfobzur3fUdE9DLlh+uZvHaAhZk5/F5bgkhAmcMS2LupDTOyehNZJg1QRnjFU8ShIi8DMwEEoG9wD1AOICqPiUiPwGuAWqASuAmVV3mHnsh8BhOsnhWVR9syTUtQbRQWZ7TmZ39HBw5CIPPdu7cTj89YCOf6m3fd4gF2bt4Y1U+BWWHiesWziXjk5k7KY3RKbHWBGVMkNma1Ma/yhJ35NNTzsin5AlHRz6FBPZbfW2d8umWfSzIzuOd9Xs4UlPH8D4xzM1M5ZLxKSTFRAb0+sYYhyUIc3zVh2HNy07z0/6t0HOgs572+P8I2MgnX2WV1Sz8cjevZeWxelcpYSHCzOG9mZuZypnDexMRZjf8GxMoliBMy9TVwsZF8OljkJ/tjnyaD6f8KKAjn3x9tbecBavyeGNVPkXlVfTqEcE3x6cwZ1IqGcmxQYnBmK7EEoRpHVXY8ak78uldCO8Bk66GKddCfFpQQqipreOTr/bxWvYu3t9QyJHaOkYlxzJnktME1atHRFDiMKazswRhTtze9e7Ip9ec16PnOCOf+owKWgglh47w1prdvJa9i3X5BwgPFc4Z2Yc5k1KZMSyJsFBrgjLmRFmCMCevdNfRkU/Vh5ypPNJPgwHToP/UoDVB5RQcYEF2Hn//Ip/iQ0dIjI7kWxNTmDsplaF9YoISgzGdiSUI03YqS5wk8dV7kJcFtVXO9t4ZTqIYMA0GTIfYfgENo7q2jqUbC3ktO4+lGwupqVPGpcUzZ1IqF49NJq57eECvb0xnYQnCBEb1Ydj9hdNfsWMZ7Frp3FcBzkioAdPdhDHVeR2gexz2Hazi71/ksyA7j417yokIC+G8jD7MzUzjtCGJhIbYvRXGNMUShAmO2hrY8yXsXO4kjB3LoNJd9S6mn5ss3BpG4nBnIaQ2pKqs332A17J28Y81uymtqKZvbBTfmuiMghqUFN2m1zOmM7AEYbxRVwf7Nrk1jOXOz/ICZ1+3ntB/2tGk0Xdsm05LXlVTy79yClmQnceHmwqpU5g0oCdzJ6Uye2w/YqKsCcoYsARh2gtVKMk9WrvY8SmUbHf2RURD2qlOc9SA6ZA8EcLbZkK/wgOHeeOLfF7L2sXWokNEhYcwa3Q/5k5KZcqgBEKsCcp0YZYgTPt1oAB2LjuaNArdhQNDIyE18+goqbTJEHlyo5RUldW7SlmQncdba3ZTfriGlPhufHtSKnMmptI/oXsbvCFjOhZLEKbjqNgPO1cc7fguWANaCxIK/cYd7cPoP+WkhtYerq7l3Q17eS1rF//esg9VOHVgL+ZmpjFrdF96RLb9KnzGtEeWIEzHVVUOuz472vHdeGhtfR9G/2knPLR2d2klb7pNULnFFXSPCGX2mH7MmZTK5IG9bIZZ06lZgjCdR/Vh2L3KZ2jtZ0eH1vYadGzHd8/0Vg2tVVWyd5TwWlYeC7/cbetsmy7BEoTpvOqH1tb3Yexc5tzMBxCT7DO0dlqrhtZWHKnhnXV7eC0rj+XbihvW2Z4zyVlnu1uELXJkOgevFgx6FrgIKGxiRbnLgVsBAcqBa1R1jbsv191WC9Q0FXxjliAMdXVQtPHYju+GobW9jk0Yfca0aGjtrv0VvL7KWWc7r+ToOttzJqUysb+ts206Nq8SxBnAQeAvTSSIaUCOqpaIyCycdahPdfflApmquq8117QEYb5G1RlKu2O5n6G1Mc7oqPqO75SJENb0QkV1dcrK7ft5LXsXb6/dQ2V1LYOSejBnUirfmpBK3zhbZ9t0PO1yTepG5XoC61Q1xX2diyUIEygHdvs0SS1vNLT2FPdejGmQOhki/d99fbCqhsVfOutsf5a7nxCB04cmMTczlXNG9iEq3JqgTMfQERLEzcAIVf2x+3o7UAIo8LSqPtOS61mCMCekYr/P9CCfukNr65yhtcnjj9Yw0k71O7Q2d98hFmTn8fqqvIZ1ti8el8zczFTGpMRZE5Rp19p1ghCRM4E/AqeparG7LUVV80WkN/Ae8FNV/biJ4+cB8wD69+8/aceOHW37JkzXUz+0tr6WkZ8FtUecfb1HHduPEdO34bDaOmXZVned7XV7qKqpY1ifaOZOSmP22H4k2ygo0w612wQhImOBN4FZqrq5iTL3AgdV9bfNXc9qECYgGg+t3bnSWRMDoNfgo9ODDJgG8QNApGGd7QXZeXyxsxSA9ITuTB2cyNTBCUwdlEBSTNP9HcYES7tMECLSH/gAuEpVl/ls7wGEqGq5+/w94Feq+k5z17MEYYKitgb2rHFrGMuPHVobm3LszXtJw9lSdIgPNxWyfGsxn23fT3lVDQBDekczzU0WUwYl0NOWUTUe8GoU08vATCAR2AvcA4QDqOpTIvJ/wLeB+jahGlXNFJFBOLUKgDDgr6r6YEuuaQnCeKJ+aG19DWPHMji4x9nXPcGZSyplEiSNoCZhOOsr4lm2vZTl24rJyt1PxZFaAEb2i2XqoASmDk5g8sBexHWzGWdN4NmNcsYEU8PQWt9Za3OP7g+LgsShDQkjV9JYfiCRJQXd+HznAapq6ggRGJ0S59QuBicwOb2XzQ9lAsIShDFeO1wG+76CwhyntlG0yXmU7TxaJjSCuoQh7O8+iE11Kaw4kMR7RfFsqe0NIeGMTY1j6uAEpg1OZNKAnjaU1rQJSxDGtFdVB51FlYo2+SSOjVCyA2eUN9SFhFMcmcbmumSyKvqwuTaFXEkjNm0Epw7py9RBCYzvH09kmCUM03qWIIzpaI5UwL7NjRJHDlqSi2gdALWEsL2uL19pCtsllbrE4SQOHM+wjPGMSe9DeGjbLulqOqfjJQhr1DSmPYro7tyklzz+mM1SXQnFW6BoE6FFGxlQsIF+ezZwfvkqQvbXwn6ozRJ20Zf93QciScNJGDSOlKETCE0a5pzXmBayBGFMRxLeDfqOcR44wwLDAWqqoHgr5bvWsWfrF1TtzqFX+RZSdqwkfGctfAh1CAe7pSBJI4hOHY30HgFJwyFxWJNTipiuzRKEMZ1BWCT0ySCmTwYxmd9p2FxYUs7adV9Q8NUXHCnIIengdoYc2sTgnR8SQU1DOY1LQ3qPdBJG0gjnkTgMomK9eDemnbA+CGO6kN2llSzfWsyKLXvJ27qB2INbGSL5jIkoYFREAf2qdxFWV3X0gNhUn6Th87NbvHdvwrQp66Q2xnyNqrJrfyXLtu5j+bZilm8tZl95JWlSyOQehczotZ/R4QUkV+8gomQLVFccPTimX6PE4dY+TmKdcOMNSxDGmGapKtv2HWLZ1mJWbC1mxbZiig85kxT27xnJhWk1zOi5n9ERBcSUb3Xv6dh0dF4qgB69jyaO3iOONlf1SPToXZnmWIIwxrRaXZ3yVeFBp4axtZiV2/dTVlkNwKCkHs60IIN6Mi2pil6HtrvDcXOO3gRYdeDoybonHE0Wvs1V0b1btW64aXuWIIwxJ622TskpOMDyrcUs3+ZMPHjQnXhweJ8YZ5bawQlMGZhAXLcwZ6nXoo1QuPGYezk4XHb0pFHxcEznuPszpp8ljiCxBGGMaXM1tXWszS9r6L/Iyi2hsroWEchwJx6cNiSBU9J7ERPlTjyoCgcLfWoabuIozIHK/UdPHt4dYpOd2XHjUp2fscnHPo+KsyTSBixBGGMC7khNHWvySp0axtZisneWcKSmjtAQYXRKXMPU5pnpPeke4WeE/cEiN2FsdCY3LMuDA/nOErHlBc4qf74iot0E4iaM2NSvP4+MCcp778gsQRhjgu5wdS2rdpawYmsxy7YWs3pXKTV1SnioMC41nmmDnZlqJ/ZvwcSDtTXOFOpl+W7SyHef5zkJpCwfDu6lfv6qBpFxbs0jxac2knzs84geAfsMOgJLEMYYz1UcqSErt4Rlbh/G2rxS6hQiwkKY1L9nQx/GuNR4IsJOYB6pmiNOTePAbjeB5DV6ng+Hir5+XFR8o2asFKcG0tCklezcwd5JWYIwxrQ75Yer+Tx3P8u2OAljQ8EBVKFbeCjj0+IZkxrH6JQ4RifHkp7Qg5CQNuhvqKnySRqNayPuo6L468d1T2i6Gas+sYR1zCVkvVxy9FngIqCwiWVHBfg9cCFQAXxfVVe5+64G7nSLPqCqzzd3PUsQxnRcpRVHWLl9P8u3FvPFzhJy9pRzpMbpd4iODCMjOZbRyXGMSXV+DkqKJrQtkkZj1ZWNkkie+9OnNnK49OvH9Uhyk0WK/yat2GQIbX+rBHqZIM4ADgJ/aSJBXAj8FCdBnAr8XlVPFZFeQBaQidOomA1MUtWS413PEoQxnUd1bR1f7T3Iut1lrM8vY21+GRsKDnC42kka3cJD3aQRy6iUOMakxDGkd3Rwpjk/csjt+/DpSK9/Xp9MqsoaHSQQ3cdPM1bK0dpIdF8IDe4UeZ42MYlIOrCwiQTxNPChqr7svt6Es471TGCmqv6Xv3JNsQRhTOdWW6dsLTrIuvwy1uUfYF1+Get3l3HIXdc7IiyEkf2cpDHaTRpD+0R7s5hSVfnxO9UP5MORg8ceIyFOkvDbjOXWTKL7QEjbvZ/2vB5ECrDL53Weu62p7V8jIvOAeQD9+/cPTJTGmHYhNEQY1ieGYX1i+NZEZ1tdnbK9+JCbLA6wNq+Mt9bs5qWVznKu4aHOMWNS4hpqGiP6xgR+ydbIGGe6kd4j/O9XdW4abNyRXl8b2bseNr8LNZXHHiehzo2EcT5JI34ATP7PNn8LXieIk6aqzwDPgFOD8DgcY0yQhYQIg5OiGZwUzSXjne+RqsrO/RVOLWN3Gevyy1iyfg+vfO587wwNEYb2jm7oBB+dEkdGcqz/+zMCRcSZFbdbPPTJ8F9GFSpLmu5UL1gNGxc5c111wgSRD6T5vE51t+XjNDP5bv8waFEZYzo0EWFAQg8GJPRg9th+gJM0dpcdZm2e0yy1Nr+MDzcVsiA7zz0GBidFOzUNN2mMSo49ehe4N2/EmSG3e6+GRaK+RvXYea/akNcJ4i3gJyLyCk4ndZmqFojIEuD/iUhPt9x5wO1eBWmM6fhEhJT4bqTEd+OC0X0BJ2kUllexNq+soaaxfGsxb36R33DcwMQejEqOZUxK/bDbOOK6t6PRSCLOtCMBENAEISIv49QEEkUkD7gHd4VEVX0KWIwzgmkLzjDXH7j79ovI/cDn7ql+par7McaYNiQi9ImNok9GFOdk9GnYXlRe1TB6al3+Ab7YWcrCLwsa9qf16sboZDdhuM1UCdEd8z6I47Eb5YwxpgVKDh1xaxlH+zV2FB9dRCk5LqqhE3x0inOvRu/YKA8jbpn2PIrJGGM6hJ49Ijh9aBKnD01q2FZWWc363WWsd5PG2vwy3s/ZS/337t4xkcd0hI9OiaNfXBTSQWahtQRhjDEnKK5bONMGJzJt8NEV8w5W1ZBTcOCYfo0PNxVS5yaNhB4RjPJJGmNS4kjt2a1dJg1LEMYY04aiI8M4Jb0Xp6QfXZ+78kgtOXsOuDf4lbE2/wDPfLyNGjdrxHULb2iWqm+mGtCre9vMP3USLEEYY0yAdYsIZWL/nkzs37Nh2+HqWjbvLWetz13hf/40lyO1x84/Vd+nMSYljoGJAZp/qgmWIIwxxgNR4aGMTY1nbGp8w7YjNXV8VVjeMJXI2vwyXlyxg6qaY+ef8r1XY2jvaMICNP+UJQhjjGknIsJCGJUcx6jkOL57irOtpraOrUWH3JqGc5Pf37J2UeHOPxUZFsLY1Dj+9l9T27wfwxKEMca0Y2GhIQzvG8PwvjHMmZQKOJMWbt93qKFP49CRmoB0cluCMMaYDiY0RBjSO5ohvaP55gS/85i2iSBMnG6MMaYjsgRhjDHGL0sQxhhj/LIEYYwxxi9LEMYYY/yyBGGMMcYvSxDGGGP8sgRhjDHGr061YJCIFAE7TvDwRGBfG4bTViyu1rG4Wsfiap3OGNcAVU3yt6NTJYiTISJZTa2q5CWLq3UsrtaxuFqnq8VlTUzGGGP8sgRhjDHGL0sQRz3jdQBNsLhax+JqHYurdbpUXNYHYYwxxi+rQRhjjPHLEoQxxhi/ulyCEJELRGSTiGwRkdv87I8UkVfd/StFJL2dxPV9ESkSkdXu48dBiOlZESkUkXVN7BcRedyN+UsRmRjomFoY10wRKfP5rO4OUlxpIrJURDaIyHoRucFPmaB/Zi2MK+ifmYhEichnIrLGjes+P2WC/vvYwriC/vvoc+1QEflCRBb62de2n5eqdpkHEApsBQYBEcAaIKNRmWuBp9znlwGvtpO4vg88GeTP6wxgIrCuif0XAm8DAkwBVraTuGYCCz34/9UPmOg+jwE2+/l3DPpn1sK4gv6ZuZ9BtPs8HFgJTGlUxovfx5bEFfTfR59r3wT81d+/V1t/Xl2tBjEZ2KKq21T1CPAKcEmjMpcAz7vPFwBnSyAWe219XEGnqh8D+49T5BLgL+pYAcSLSL92EJcnVLVAVVe5z8uBHKDxepBB/8xaGFfQuZ/BQfdluPtoPGom6L+PLYzLEyKSCswG/q+JIm36eXW1BJEC7PJ5ncfXf1EayqhqDVAGJLSDuAC+7TZLLBCRtADH1BItjdsLU90mgrdFZFSwL+5W7SfgfPv05elndpy4wIPPzG0uWQ0UAu+papOfVxB/H1sSF3jz+/gYcAtQ18T+Nv28ulqC6Mj+CaSr6ljgPY5+SzBftwpnfplxwBPA34N5cRGJBl4HblTVA8G89vE0E5cnn5mq1qrqeCAVmCwio4Nx3ea0IK6g/z6KyEVAoapmB/pa9bpagsgHfDN9qrvNbxkRCQPigGKv41LVYlWtcl/+HzApwDG1REs+z6BT1QP1TQSquhgIF5HEYFxbRMJx/gi/pKpv+CniyWfWXFxefmbuNUuBpcAFjXZ58fvYbFwe/T5OBy4WkVycZuizROTFRmXa9PPqagnic2CoiAwUkQicTpy3GpV5C7jafT4H+EDdHh8v42rUTn0xTjuy194CrnJH5kwBylS1wOugRKRvfburiEzG+X8e8D8q7jX/BOSo6iNNFAv6Z9aSuLz4zEQkSUTi3efdgHOBjY2KBf33sSVxefH7qKq3q2qqqqbj/I34QFWvaFSsTT+vsBM9sCNS1RoR+QmwBGfk0LOqul5EfgVkqepbOL9IL4jIFpyO0MvaSVzXi8jFQI0b1/cDHZeIvIwzuiVRRPKAe3A67FDVp4DFOKNytgAVwA8CHVML45oDXCMiNUAlcFkQkjw43/CuBNa67dcAdwD9fWLz4jNrSVxefGb9gOdFJBQnIf1NVRd6/fvYwriC/vvYlEB+XjbVhjHGGL+6WhOTMcaYFrIEYYwxxi9LEMYYY/yyBGGMMcYvSxDGGGP86lLDXI05ESJSC6z12fSKqj7kVTzGBIsNczWmGSJyUFWjvY7DmGCzJiZjTpCI5IrIb0Rkrbt+wBB3e7qIfOBO5PYvEenvbu8jIm+6E+KtEZFp7va/i0i2OGsPzHO3hYrIcyKyzj3/z7x7p6arsiYmY5rXzecOZIBfq+qr7vMyVR0jIlfhzLR5Ec5kd8+r6vMi8kPgceCb7s+PVPVS9y7d+lrJD1V1vzutw+ci8jqQDqSo6miA+qkfjAkma2IyphlNNTG5k6adparb3Mnw9qhqgojsA/qparW7vUBVE0WkCEj1meSt/jz3Ape6L9OB84FNQBbO1ByLgHdVtakpno0JCGtiMubkaBPPW0REZgLnAFPdqba/AKJUtQQYB3wIzKfpBWKMCRhLEMacnO/6/FzuPl/G0UnSLgc+cZ//C7gGGvoY4nCmYy5R1QoRGYGzDCnuVNshqvo6cCfOEqvGBJU1MRnTDD/DXN9R1dvcJqZXgVlAFfA9Vd0iIgOAPwOJQBHwA1XdKSJ9gGdw1h6vxUkWq3AW50nHaVaKB+4FStxz1H+Ju11V3w7g2zTmayxBGHOC3ASRqar7vI7FmECwJiZjjDF+WQ3CGGOMX1aDMMYY45clCGOMMX5ZgjDGGOOXJQhjjDF+WYIwxhjj1/8HLu+M4cXfkZEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"Loss Train\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Loss Test\")\n",
    "\n",
    "plt.title('Transformer')\n",
    "plt.ylabel('Métricas')\n",
    "plt.xlabel('Epocas')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eTc8GFbByexu",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1654213336046,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "eTc8GFbByexu"
   },
   "outputs": [],
   "source": [
    "def translate(input_sentence):\n",
    "    if type(input_sentence) != str:\n",
    "        return TypeError(\"input_sentence must be a str\")\n",
    "    else:\n",
    "        # Se construye la tokenización del input\n",
    "        input_sentence = input_sentence.split()\n",
    "        tokenized_input_sentence = [source_token_dict_inv[1]]\n",
    "        \n",
    "        for i in range(len(input_sentence)):\n",
    "            tokenized_input_sentence.append(input_sentence[i])\n",
    "\n",
    "        tokenized_input_sentence = tokenized_input_sentence + ['<TOKEN_NULO>']*(max_len-len(tokenized_input_sentence))\n",
    "        tokenized_input_sentence[len(input_sentence)+1] = source_token_dict_inv[2]\n",
    "        tokenized_input_sentence = [source_token_dict[word] for word in tokenized_input_sentence]\n",
    "        #Se construye la tokenización de la predicción\n",
    "        decoded_sentence = target_token_dict_inv[1]\n",
    "        for i in range(max_len):\n",
    "            tokenized_target_sentence = decoded_sentence.split() + ['<TOKEN_NULO>']*(max_len-len(decoded_sentence.split()))\n",
    "            tokenized_target_sentence = [target_token_dict[word] for word in tokenized_target_sentence]\n",
    "            predictions = transformer([np.array([tokenized_input_sentence]),\n",
    "                                       np.array([tokenized_target_sentence])])\n",
    "            sampled_token_index = np.argmax(predictions[0][i])\n",
    "            sampled_token = target_token_dict_inv[sampled_token_index]\n",
    "            decoded_sentence += \" \" + sampled_token\n",
    "            if sampled_token == target_token_dict_inv[2]:\n",
    "                return(decoded_sentence)\n",
    "        return(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "uPEEvwmDzRtF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 611,
     "status": "ok",
     "timestamp": 1654213336647,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "uPEEvwmDzRtF",
    "outputId": "edd54bdf-4ed4-44eb-fec5-fce8a45fe980"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<TOKEN_INICIO> el mundo está en el banco. <TOKEN_FIN>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"the world is in danger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7ae308a-4d15-4237-9cc2-e31bed6ffb04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1654213336648,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "c7ae308a-4d15-4237-9cc2-e31bed6ffb04",
    "outputId": "bf568e52-3460-48bc-9ccc-fe92be7e36b8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<TOKEN_INICIO> tom es una vez. <TOKEN_FIN>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"tom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1QwfPFMUsotY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 371,
     "status": "ok",
     "timestamp": 1654213337010,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "1QwfPFMUsotY",
    "outputId": "db1e4b54-3ca7-4047-c551-bed00a176fe5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<TOKEN_INICIO> el juego está en el banco. <TOKEN_FIN>'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"the game is in danger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6rKECsF5sqyg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 926,
     "status": "ok",
     "timestamp": 1654213337932,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "6rKECsF5sqyg",
    "outputId": "aab193c8-de60-47a0-8e7b-f7c07c2e4fbf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<TOKEN_INICIO> ¿qué hizo eso hoy? <TOKEN_FIN>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"what did she do today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "kO2AR61hc0XV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 691,
     "status": "ok",
     "timestamp": 1654213338621,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "kO2AR61hc0XV",
    "outputId": "d3aa91ac-d7b1-44ea-8614-5592ca44f970"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<TOKEN_INICIO> no dejes que te va a ti mismo. <TOKEN_FIN>'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"don't let them fool you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "OPZZpFNnc8Fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 448,
     "status": "ok",
     "timestamp": 1654213339063,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "OPZZpFNnc8Fd",
    "outputId": "d42f640f-d63b-4ec8-e69f-808f11e8f2cd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<TOKEN_INICIO> su discurso se quedó al árbol. <TOKEN_FIN>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"her speech moved the audience\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "-pNy2DIZdAAO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 893,
     "status": "ok",
     "timestamp": 1654213339953,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "-pNy2DIZdAAO",
    "outputId": "91f559fc-6a3b-42ab-edbc-a9b35c3a44c2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<TOKEN_INICIO> a casa de casa. <TOKEN_FIN>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"home\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1K4XpgxJdDKO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 478,
     "status": "ok",
     "timestamp": 1654213340429,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "1K4XpgxJdDKO",
    "outputId": "753b7e49-bde5-4303-dd0b-faa23cd82de8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<TOKEN_INICIO> lleva en la pared. <TOKEN_FIN>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"sun in the beach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dK3_1CMYdI0W",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 1128,
     "status": "ok",
     "timestamp": 1654213341553,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "dK3_1CMYdI0W",
    "outputId": "1df77000-968c-4c06-cec2-b09891853613"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<TOKEN_INICIO> este perro es mi amigo de mi amigo. <TOKEN_FIN>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"this dog is my friend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "FYV7TUEtdNLV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 399,
     "status": "ok",
     "timestamp": 1654213341950,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "FYV7TUEtdNLV",
    "outputId": "a0b19618-9852-4905-bf12-0c6c3c61bd60"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<TOKEN_INICIO> él siempre está en tiempo. <TOKEN_FIN>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"he's always on time.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2li6nis_dZB9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 374,
     "status": "ok",
     "timestamp": 1654213342320,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "2li6nis_dZB9",
    "outputId": "efc9431c-af09-44d3-85a6-ea1ab36bc635"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<TOKEN_INICIO> casi nunca he oído hoy. <TOKEN_FIN>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"i almost never remember dreams.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "iKPsD2Pwdevl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1654213342575,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "iKPsD2Pwdevl",
    "outputId": "c3b6a7e3-0e60-4d99-ce99-85de9f2e3204"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<TOKEN_INICIO> ¿sabes que ir hoy? <TOKEN_FIN>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"do you need to leave today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "UsNwxCOqbDtg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 1367,
     "status": "ok",
     "timestamp": 1654213343938,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "UsNwxCOqbDtg",
    "outputId": "bf493270-f992-46cd-dc99-5e14bc47a0e5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<TOKEN_INICIO> tú tú tú lo que estás mintiendo. <TOKEN_FIN>'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"you reap what you sow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "Wjldd0A3a1OA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1654213343939,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "Wjldd0A3a1OA",
    "outputId": "a18f22f6-1e06-442c-bfb2-e16465e657fe"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<TOKEN_INICIO> ¿te debo ir? <TOKEN_FIN>'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"should i go?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "pwgJWihRbRvY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 138332,
     "status": "ok",
     "timestamp": 1654213482264,
     "user": {
      "displayName": "MATIAS ALFONSO PALMA MANTEROLA",
      "userId": "11730898500476813827"
     },
     "user_tz": 240
    },
    "id": "pwgJWihRbRvY",
    "outputId": "29785eca-bea2-4862-c6f6-3c325ce55a5f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you reap what you sow.\n",
      "<TOKEN_INICIO> tú no te va lo que pasó. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "you need a job.\n",
      "<TOKEN_INICIO> necesitas un trabajo. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "let's make it brief.\n",
      "<TOKEN_INICIO> vamos a hacer extraño. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "keep children away from the pond.\n",
      "<TOKEN_INICIO> quédate los niños del río. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "he accused the man of stealing.\n",
      "<TOKEN_INICIO> él dejó el hombre de que se fue. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "there's something i should tell you.\n",
      "<TOKEN_INICIO> hay algo que debería decir que te lo hiciera. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "she didn't read the book.\n",
      "<TOKEN_INICIO> ella no lee el libro. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "turn on your headlights.\n",
      "<TOKEN_INICIO> pon los ojos en los demás. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "they consider him unfit for the job.\n",
      "<TOKEN_INICIO> ellos no lo hicieron para el trabajo. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "he sang some old songs.\n",
      "<TOKEN_INICIO> él cantó algo de nueva canción. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "should i go?\n",
      "<TOKEN_INICIO> ¿te debo ir? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "we danced all night long.\n",
      "<TOKEN_INICIO> fuimos toda la noche. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom never told mary about john.\n",
      "<TOKEN_INICIO> tom nunca le dijo a mary sobre john. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "why did he do such a thing?\n",
      "<TOKEN_INICIO> ¿por qué hizo él tan rápido por favor. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "so you give up, right?\n",
      "<TOKEN_INICIO> ¿no te ves ¿verdad? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "do as i told you.\n",
      "<TOKEN_INICIO> haz lo que te lo te lo mismo. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "the heat was unbearable.\n",
      "<TOKEN_INICIO> el mundo fue un mentiroso. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "give it to whoever needs it.\n",
      "<TOKEN_INICIO> dame que lo que lo que lo hizo eso. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "what happened to you two?\n",
      "<TOKEN_INICIO> ¿qué le pasó a usted más de lo que quieras. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "do you believe in god?\n",
      "<TOKEN_INICIO> ¿sabes en la pared. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "do you think i'm stupid?\n",
      "<TOKEN_INICIO> ¿sabes que soy estúpido. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom does outstanding work.\n",
      "<TOKEN_INICIO> tom está un trabajo de trabajo. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "you should take my advice.\n",
      "<TOKEN_INICIO> deberías tomar mi consejo. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "this book belongs to tom.\n",
      "<TOKEN_INICIO> este libro se sentó en tom. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "she greeted me with a big smile.\n",
      "<TOKEN_INICIO> ella me habló con una gran vez. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "they accomplished their mission.\n",
      "<TOKEN_INICIO> ellos se puso a su fiesta. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom wanted to see mary happy.\n",
      "<TOKEN_INICIO> tom quería ver a mary feliz. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "we've had some very cold winters.\n",
      "<TOKEN_INICIO> hemos visto algo muy frío. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom can't take less.\n",
      "<TOKEN_INICIO> tom no puede tomar la cabeza. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i am memorizing a text.\n",
      "<TOKEN_INICIO> me estoy escribiendo un poco. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom forgot to pay the bill.\n",
      "<TOKEN_INICIO> tom se olvidó de pagar la cuenta. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "who told you this?\n",
      "<TOKEN_INICIO> ¿quién te dijo esto? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i have mentioned it to you before.\n",
      "<TOKEN_INICIO> lo he ido a que antes. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "he is a very sincere person.\n",
      "<TOKEN_INICIO> él es una persona muy cansado. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "the photo was a hoax.\n",
      "<TOKEN_INICIO> la caja era un segundo. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "have another.\n",
      "<TOKEN_INICIO> ¿has un inglés. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i study mathematics.\n",
      "<TOKEN_INICIO> yo yo estudio en las cinco. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "he hasn't come yet.\n",
      "<TOKEN_INICIO> él no ha hecho eso. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "the horse is a useful animal.\n",
      "<TOKEN_INICIO> el caballo es un hombre grande. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "the woman is drinking water now.\n",
      "<TOKEN_INICIO> la mujer está leyendo el agua. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "write the date of your birth.\n",
      "<TOKEN_INICIO> escribe la sopa de tu habitación? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom is listening to music.\n",
      "<TOKEN_INICIO> tom está escuchando música. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "have you read this report?\n",
      "<TOKEN_INICIO> ¿has leído este libro? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "who's tom? is he your new boyfriend?\n",
      "<TOKEN_INICIO> ¿quién es a tom es tu nuevo profesor. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i don't know what time it is.\n",
      "<TOKEN_INICIO> no sé qué hora es hora de eso. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom isn't a kid anymore.\n",
      "<TOKEN_INICIO> tom no es más alto de idea. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "can i borrow this?\n",
      "<TOKEN_INICIO> ¿puedo tomar esto? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "please forget it.\n",
      "<TOKEN_INICIO> por favor, lo hizo de ello. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i didn't know you were busy.\n",
      "<TOKEN_INICIO> no sabía que estabas ocupado. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom was naive.\n",
      "<TOKEN_INICIO> tom era ingenuo. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i agree with that statement.\n",
      "<TOKEN_INICIO> estoy de acuerdo con ese boleto. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "are you going to be ok?\n",
      "<TOKEN_INICIO> ¿vas a estar ahora? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i'll stay home today.\n",
      "<TOKEN_INICIO> me siento en casa hoy. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "what happened?\n",
      "<TOKEN_INICIO> ¿qué ha sido esto? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "he wrote it hurriedly.\n",
      "<TOKEN_INICIO> él lo ha hecho a mí. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom pinched mary.\n",
      "<TOKEN_INICIO> tom habló con mary. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "this car is in good condition.\n",
      "<TOKEN_INICIO> este auto está en buena escritorio. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i still have some doubts.\n",
      "<TOKEN_INICIO> todavía tengo un poco de hambre. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i tried writing a novel.\n",
      "<TOKEN_INICIO> he oído que me siento una película. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "come this way.\n",
      "<TOKEN_INICIO> ven por este momento. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom pulled the door half shut.\n",
      "<TOKEN_INICIO> tom puso la puerta al colegio. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "do i have to take off my shoes here?\n",
      "<TOKEN_INICIO> ¿tienes que dar los zapatos de los zapatos. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "please help me with my homework.\n",
      "<TOKEN_INICIO> por favor, dime que mis padres. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i know how it is.\n",
      "<TOKEN_INICIO> sé cómo es ella. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom raised his son without any help.\n",
      "<TOKEN_INICIO> tom dejó su hijo sin nada. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i'm coming.\n",
      "<TOKEN_INICIO> estoy de hambre. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "don't forget to take your vitamins.\n",
      "<TOKEN_INICIO> no te olvides de tomar tu mañana? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "didn't you learn that in school?\n",
      "<TOKEN_INICIO> ¿no has oído ese del árbol. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i had a phone call from him.\n",
      "<TOKEN_INICIO> tuve una taza de mary. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "he kissed me on the forehead.\n",
      "<TOKEN_INICIO> me dio la semana en la ciudad. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "could you please play a tango?\n",
      "<TOKEN_INICIO> ¿podrías saber un minuto. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "you can't blame me for that.\n",
      "<TOKEN_INICIO> no te puedes soportar por eso. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "this is a very mild coffee.\n",
      "<TOKEN_INICIO> este es un estudiante muy duro. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "he was late to his own wedding.\n",
      "<TOKEN_INICIO> él fue tarde a su propio hijo. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "you can rely on her.\n",
      "<TOKEN_INICIO> puedes usted el mundo en ella. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "please write a letter to me.\n",
      "<TOKEN_INICIO> por favor, toma una carta a la carta. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "the grapes ripened well that summer.\n",
      "<TOKEN_INICIO> la comida se puso el año pasado. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom told mary that he was canadian.\n",
      "<TOKEN_INICIO> tom le dijo a mary que era canadiense. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom is a quadriplegic.\n",
      "<TOKEN_INICIO> tom es un segundo. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "do you speak filipino?\n",
      "<TOKEN_INICIO> ¿sabes hablar mañana? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "can we talk later?\n",
      "<TOKEN_INICIO> ¿puedes hablar más que más tarde? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i don't know what you mean.\n",
      "<TOKEN_INICIO> no sé qué quiere qué quiere decir. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "there is but one alternative.\n",
      "<TOKEN_INICIO> hay que una decisión un abogado? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom cheated on his history test.\n",
      "<TOKEN_INICIO> tom se dio el gato de su madre. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "he is likely to arrive soon.\n",
      "<TOKEN_INICIO> él lleva haber hecho pronto. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "what was it that he was looking for?\n",
      "<TOKEN_INICIO> ¿qué fue lo que era ahora? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "give me a break.\n",
      "<TOKEN_INICIO> dame un descanso. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "she decided on the red coat.\n",
      "<TOKEN_INICIO> ella decidió en el tren del abrigo. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "come here, the both of you.\n",
      "<TOKEN_INICIO> ven aquí por aquí a los demás. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "the party's on monday.\n",
      "<TOKEN_INICIO> la es el lunes. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "it's finally over.\n",
      "<TOKEN_INICIO> por favor, finalmente se ha hecho. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "since i was sick, i didn't go.\n",
      "<TOKEN_INICIO> yo estaba realmente no yo no pude ir. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom was supposed to be here by 2:30.\n",
      "<TOKEN_INICIO> tom se fue a estar aquí a las dos y media. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "mary went to the tanning salon.\n",
      "<TOKEN_INICIO> mary fue a la policía a la ventana. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "she sent her son for a doctor.\n",
      "<TOKEN_INICIO> le dio a su hijo a un médico. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "now he tells me the truth.\n",
      "<TOKEN_INICIO> ahora me dijo la verdad. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i did that during summer vacation.\n",
      "<TOKEN_INICIO> lo hice durante las dos años. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "none of us are busy right now.\n",
      "<TOKEN_INICIO> ¿no estamos de estamos haciendo ahora ahora. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "there're no lights.\n",
      "<TOKEN_INICIO> hay no la cocina. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "best of luck to you.\n",
      "<TOKEN_INICIO> mejor de verdad te va a ti. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "is this really spaghetti?\n",
      "<TOKEN_INICIO> ¿es realmente este libro? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i know him by sight.\n",
      "<TOKEN_INICIO> sé que él la mano a la <TOKEN_FIN>\n",
      "\n",
      "\n",
      "put the book on the top shelf.\n",
      "<TOKEN_INICIO> pon el libro en el libro de la ciudad. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom isn't fighting, is he?\n",
      "<TOKEN_INICIO> tom no es nada de tom ¿verdad? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "quiet down, please.\n",
      "<TOKEN_INICIO> la guerra por favor. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i'm horrified.\n",
      "<TOKEN_INICIO> estoy borracho. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom really is an idiot.\n",
      "<TOKEN_INICIO> tom realmente es un abogado. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "why don't you accept that?\n",
      "<TOKEN_INICIO> ¿por qué no te quedes eso? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "send him in.\n",
      "<TOKEN_INICIO> haz lo que le ha hecho. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "what time does the bank open?\n",
      "<TOKEN_INICIO> ¿a qué hora empieza el banco. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "he was unconscious for three days.\n",
      "<TOKEN_INICIO> él fue un día para tres días. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "my house is close to a bus stop.\n",
      "<TOKEN_INICIO> mi casa está cerca de autobús. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "make a copy of this report.\n",
      "<TOKEN_INICIO> haz una vez de este problema? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i lost my sunglasses.\n",
      "<TOKEN_INICIO> perdí mi vaso de mi lado. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "you just missed it.\n",
      "<TOKEN_INICIO> solo lo has hecho de eso. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i am glad to run into you here.\n",
      "<TOKEN_INICIO> estoy feliz de que me da aquí. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom finished his beer.\n",
      "<TOKEN_INICIO> tom fue de su cerveza. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "he will never break his promise.\n",
      "<TOKEN_INICIO> él nunca se llama su promesa. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "we've arrived.\n",
      "<TOKEN_INICIO> hemos perdido el mundo. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom's feet felt numb.\n",
      "<TOKEN_INICIO> el mundo de tom se puso de boston. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i'm going to tom's house to study.\n",
      "<TOKEN_INICIO> voy a la casa de tom a la casa a la casa de que mary voy a\n",
      "\n",
      "\n",
      "tom is a football player.\n",
      "<TOKEN_INICIO> tom es un país de cabeza. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "he talks a lot.\n",
      "<TOKEN_INICIO> él habla mucho. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "do you smell anything?\n",
      "<TOKEN_INICIO> ¿sabes algo? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "perhaps you've made a mistake.\n",
      "<TOKEN_INICIO> quizá has hecho un error. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i should've never come here.\n",
      "<TOKEN_INICIO> debería haber hecho nunca aquí. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "how much should i be feeding my dog?\n",
      "<TOKEN_INICIO> ¿cuánto cuesta mi perro? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "where did you get on this bus?\n",
      "<TOKEN_INICIO> ¿dónde te ves en este hospital. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i just want to ask you a question.\n",
      "<TOKEN_INICIO> solo quiero hacer una pregunta. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "it's not that big a deal.\n",
      "<TOKEN_INICIO> no es tan gran médico. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "the hotel is down there.\n",
      "<TOKEN_INICIO> el hombre está allí. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "somebody opened the door.\n",
      "<TOKEN_INICIO> alguien abrió la puerta. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "all men are equal before god.\n",
      "<TOKEN_INICIO> todos los hombres son detrás de boston. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "do you live alone?\n",
      "<TOKEN_INICIO> ¿sabes alguna vez? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "that chair goes in the corner.\n",
      "<TOKEN_INICIO> esa gran me va en la ciudad. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "this story is too predictable.\n",
      "<TOKEN_INICIO> esta historia es demasiado pared. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "there are some eggs in the box.\n",
      "<TOKEN_INICIO> hay algunos en los ojos en la caja. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "who looks after the children?\n",
      "<TOKEN_INICIO> ¿quién parece las gafas. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "you could start your own company.\n",
      "<TOKEN_INICIO> puedes aprender tu propio madre. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "why should i listen to you?\n",
      "<TOKEN_INICIO> ¿por qué debería dejar que te guste. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i'm hurt.\n",
      "<TOKEN_INICIO> estoy herido. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "were you busy yesterday?\n",
      "<TOKEN_INICIO> ¿te has ocupado hoy? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i think i'm going mad.\n",
      "<TOKEN_INICIO> creo que voy a hacer <TOKEN_FIN>\n",
      "\n",
      "\n",
      "everyone dreams.\n",
      "<TOKEN_INICIO> todos se quedó años. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "the boy sat on a chair.\n",
      "<TOKEN_INICIO> el niño se sentó en una silla. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "she's my sister.\n",
      "<TOKEN_INICIO> ella es mi hermana. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "he stole money from me.\n",
      "<TOKEN_INICIO> él me dio dinero de mí. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "it's the smart thing to do.\n",
      "<TOKEN_INICIO> es lo que hacer. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom is absolutely terrified.\n",
      "<TOKEN_INICIO> tom es muy bien el dedo. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i don't know what that is.\n",
      "<TOKEN_INICIO> no sé lo que es eso. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "the notice was badly printed.\n",
      "<TOKEN_INICIO> la chica estaba en tokio. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "he delivers newspapers.\n",
      "<TOKEN_INICIO> él se quedó en tokio. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom's dead.\n",
      "<TOKEN_INICIO> tom está muerto. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "it's not a bomb.\n",
      "<TOKEN_INICIO> no es un boleto. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "she stopped sewing and had some tea.\n",
      "<TOKEN_INICIO> ella se dejó de acuerdo y un poco de té. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "do you have this in my size?\n",
      "<TOKEN_INICIO> ¿tienes este en mi madre. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i owe you an explanation.\n",
      "<TOKEN_INICIO> te debo una carta. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i hired tom.\n",
      "<TOKEN_INICIO> yo le pedí a tom. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "perhaps the book will prove useful.\n",
      "<TOKEN_INICIO> puede que el libro de fumar bien. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "we're not your enemies.\n",
      "<TOKEN_INICIO> no estamos tu profesor. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i don't know which one to choose.\n",
      "<TOKEN_INICIO> no sé qué un trozo de novia. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "we can't talk here.\n",
      "<TOKEN_INICIO> no podemos hablar aquí. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "it was a difficult game.\n",
      "<TOKEN_INICIO> fue un día difícil de juego. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "when did you learn to drive?\n",
      "<TOKEN_INICIO> ¿cuándo te has oído a nosotros? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i have a bone to pick with you.\n",
      "<TOKEN_INICIO> tengo una historia con vos. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i tried to hide my disappointment.\n",
      "<TOKEN_INICIO> espero que mi promesa. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "your shirt is stained.\n",
      "<TOKEN_INICIO> tu nueva mesa está en el mundo. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "where are the kids?\n",
      "<TOKEN_INICIO> ¿dónde están los ojos. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i am getting dressed.\n",
      "<TOKEN_INICIO> me estoy haciendo los ojos. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "all i want is to be left alone.\n",
      "<TOKEN_INICIO> todo lo que quiero estar solo. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "she is always smiling.\n",
      "<TOKEN_INICIO> ella siempre está sonriendo. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "we rented a canoe.\n",
      "<TOKEN_INICIO> jugamos un árbol. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "you're finished already.\n",
      "<TOKEN_INICIO> ya ha hecho de eso. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "are you calling me a liar?\n",
      "<TOKEN_INICIO> ¿estás buscando un segundo. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "report for duty monday morning.\n",
      "<TOKEN_INICIO> pon el mundo se llama el lunes por la mañana. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "who is that person?\n",
      "<TOKEN_INICIO> ¿quién es ese bebé. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "what time is it now?\n",
      "<TOKEN_INICIO> ¿a qué hora es ahora? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "what's new with you?\n",
      "<TOKEN_INICIO> ¿qué es nuevo con esto? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "you had better do what they say.\n",
      "<TOKEN_INICIO> tienes mejor que lo que lo que lo lo que lo que lo has dicho lo has\n",
      "\n",
      "\n",
      "this lake is deep.\n",
      "<TOKEN_INICIO> este es el lago de ella. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "please wish me luck.\n",
      "<TOKEN_INICIO> por favor, ¿me ha hecho un ayuda. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "she was absorbed in her work.\n",
      "<TOKEN_INICIO> ella fue capaz de su trabajo. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "please explain how to get there.\n",
      "<TOKEN_INICIO> por favor, vamos a hacer allí. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "his speech was too short.\n",
      "<TOKEN_INICIO> su discurso fue demasiado abierta. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i know tom is happy.\n",
      "<TOKEN_INICIO> sé que tom es feliz. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "why shouldn't i do that?\n",
      "<TOKEN_INICIO> ¿por qué no debería hacer eso? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "get me a beer.\n",
      "<TOKEN_INICIO> dame una cerveza. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "it's snowing.\n",
      "<TOKEN_INICIO> está borracho. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "those aren't mine.\n",
      "<TOKEN_INICIO> esas no son mío. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "look at me when i talk to you!\n",
      "<TOKEN_INICIO> mira cuando yo que yo te voy a ayudar. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom won't go alone.\n",
      "<TOKEN_INICIO> tom no va a ir solo. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i'll be with you as soon as i can.\n",
      "<TOKEN_INICIO> estaré con usted como si yo pueda. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i like drinking beer and wine.\n",
      "<TOKEN_INICIO> me gusta leer y japón. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "you're useless.\n",
      "<TOKEN_INICIO> eres un poco de nada. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "that patient may die at any time.\n",
      "<TOKEN_INICIO> ese perro puede aprender en cualquier vez. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "the young girl remained silent.\n",
      "<TOKEN_INICIO> la chica se quedó en china. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "for here, or to go?\n",
      "<TOKEN_INICIO> por aquí o o para ir? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "i can't stop him.\n",
      "<TOKEN_INICIO> no puedo dejar de él. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "why would tom want to kill anyone?\n",
      "<TOKEN_INICIO> ¿por qué tom quiere comer tom? <TOKEN_FIN>\n",
      "\n",
      "\n",
      "tom is probably still hiding.\n",
      "<TOKEN_INICIO> tom todavía está haciendo despierto. <TOKEN_FIN>\n",
      "\n",
      "\n",
      "please add my name to the list.\n",
      "<TOKEN_INICIO> por favor, dime mi nombre de la lista. <TOKEN_FIN>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(x1_test)):\n",
    "    sequence = x1_test[i]\n",
    "    decode_seq = [source_token_dict_inv[j] for j in x1_test[i]]\n",
    "    decode_seq = decode_seq[1:]\n",
    "    decode_seq = [word for word in decode_seq if word[-1]!= '>']\n",
    "    print(\" \".join(decode_seq))\n",
    "    print(translate(\" \".join(decode_seq)))\n",
    "    print('\\n')\n",
    "    if i == 200:\n",
    "      break"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Tarea2_copia_29-5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
